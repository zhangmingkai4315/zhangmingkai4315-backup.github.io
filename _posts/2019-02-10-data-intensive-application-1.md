---
layout: post
title: 《数据密集型应用设计》第一部分读书笔记
date: 2019-02-10T11:32:41+00:00
author: mingkai
permalink: /2019/02/data-intensive-application-1
categories:
  - Architecture
  - 读书笔记
---

## 《数据密集型应用设计》第一部分读书笔记

### 第一章  可靠可扩展和可维护的系统
---
最近几年开源的数据软件及概念层出不穷，比如大数据，最终一致性，分片，Hadoop, Spark , MongoDB 等等，这些出现的原因：

- 大型互联网公司用户访问越来越多，处理能力需求不断推动技术的出现
- 为满足业务多变及市场需求要求开发周期越来越短，数据模型足够灵活。
- 开源软件越来越多，越来越丰富
- 并行技术的推动，充分利用系统资源
- 高可用，可维护性的要求

**数据密集型应用**： 指的是如果数据在应用中占用较大的因素，比如大量的数据处理，复杂的数据结构，使得数据容易成为程序运行的瓶颈。为了满足这些应用需求，出现了比如NoSQL， 消息队列，缓存，搜索引擎，流式计算 批量计算等相关的技术，许多应用是结合多个技术与一体。**其实对于不断改变的技术，背后的一些核心思想是没有太多变化的，这些背后的基本概念，同样适用于新的平台软件及工具**


开发一套大型的应用系统，其中涉及数据处理及存储部分主要涉及的几个方面包括：
- 数据库系统， 存储数据
- 缓存系统，缓存数据，减少数据库查询，提高查询性能
- 搜索系统,  全文检索或者特殊的搜索查询
- 批处理系统： 数据的批量处理，统计分析等
- 流式处理系统：数据的流式处理和分析


![](https://cdn-images-1.medium.com/max/1600/1*K6M-x-6e39jMq_c-2xqZIQ.png)


上述图中代表了一个典型的应用构建，缓存和全文检索分别处于不同的位置，通过独立的组件实现，但是核心代码中已明确了数据更新的流动方向，消息队列中保存了待发送的邮件等其他的任务。服务接口API会隐藏内部的实施细节，通过不同组件实现不同的功能。


- 可靠性： 系统能够保持持久可靠运行，不管是否出现硬件错误，软件错误或者人为错误等。
- 可扩展性： 应该对于存储，流量和复杂度增加的情况下实现系统规模化增加
- 可维护性： 系统的运行和监测得到可靠的维护，维护复杂度可接受。


可靠性不仅仅是产品的运行稳定，同样也关系着整个企业的利益相关。有时候会在特殊的情况下**牺牲一部分的可靠性来降低实际的运行花费**（服务可能盈利少或使用人员较少）和开发的花费（原型系统）

可扩展性代表了系统可容纳的负载水平，首先要确定负载的参数，这与系统本身的运行服务相关联，比如QPS, TPS等等。同时对于系统的性能需要持续监控，比如增加负载水平的同时，资源的使用情况 性能是否发生改变。比如Hadoop系统的吞吐量指标（对于某一个特殊大小的任务执行的时间），服务的响应时间等等。

延迟和响应时间的差异： 延迟一般包含了服务的网络延迟和队列延迟。

使用**平均值和百分位值来度量指标**，其中百分位可以选择P95或者P90来定义90%的指标， 比如亚马逊定义影响的话 一般是以 99.9%来定义，1000个访问中只有一个不符合要求。 太高的指标需要投入的太多。同时对于后端应用来说，一个用户的请求可能同时需要多个API调用，最慢的调用可能导致整个的请求缓慢，因此后端应用更需要关注响应时间。


可扩展性需要关注当负载水平增加到一定程度后，仍旧可以满足特定的性能指标。

- **Scale Up 垂直扩展** ： 增加更多资源，比如扩展内存等。
- **Scale Out 水平扩展** ： 分布式多节点部署等。

对于服务部署可以结合两者同时实施，有可能大容量机器还比一些小机器组合更加适合。**对于无状态的服务，借助于多台机器比较容易，但是对于有状态保存的服务，垂直扩展更加容易实施。**







### 第二章 数据模型与查询语言
---

本章主要介绍数据模型的定义和查询语言的使用，比较不同的数据模型（关系模型，文档模型以及图模型）使用场景和优劣。 复杂应用程序一般都会有很多的中间层，比如在存储API上面构建应用API, **每层通过一个简单的数据模型来隐藏底层的复杂度，抽象可以使得系统运行更加高效简单**。


#### 1. 关系模型和文档模型


NoSQL： 不仅仅是SQL，2009年作为一个Twitter上的标签逐渐被大家熟知，用来代表的是某些分布式，开源以及非关系数据库技术，采用NoSQL的主要优势：

- 更好的扩展性
- 大部分都是免费开源的产品
- 支持一些特殊的查询操作
- 动态和更合适的数据模型

相对于关系模型，查询信息一般需要多次查询才可以，使用主键和外键的方式在不同的表结构之间建立联系。而文档模型则一般使用JSON等方式来存储数据，每个数据包含几乎所有相关联的信息，一次查询即可。

> 如果数据记录多是一对多的关系或者记录之间没有关系，则文档模型会更有优势


但是对于文档数据模型的问题在于，假如对于一个比如职位的信息更新，地区信息的更新，可能会涉及大量使用这些信息的文档的修改，而关系数据库则只需要修改一次可以，保证了数据的一致性。特别是多对一的关系下，关系数据库更好的支持数据的修改和更新操作。

- 关系数据库具有更好的联结操作，对于多对一或者多对多的关系处理上更好。
- 文档数据库一般可以实现更快的性能（不需要关联操作）。但是一旦涉及多对多的问题，则可能需要应用程序来处理数据一致性的问题，降低性能。
- 文档数据库的模式可以很灵活，可以插入不同类型的数据，不需要定义Schema, 数据转换更加灵活简单，而关系数据库则涉及表转换操作，比如MySQL在执行AlterTable操作的时候，会将整个表复制，可能导致很长时间的停机

#### 2. 数据查询

- **声明式查询语言**： 比如SQL语句，制定所需的数据模式，满足什么样的条件，如何处理数据，而不需要告诉如何处理，底层的查询优化器会决定如何处理。
- **命令式查询语言**： 指定如何处理更像是编程语言本身的处理逻辑定义。

另一个例子是声明式的CSS或是命令式的JS来更新样式，优势自然是声明式的更加简练有效。

MapReduce是一种介于声明式和命令式的执行模式，提供部分代码片段允许查询时候执行，比如下面的单词计数器的MapReduce实现，每个文件单独的执行Map函数，返回对应的数据，Reduce针对Key相同的数据进行聚合操作，获得结果。
![](https://i.stack.imgur.com/199Q1.png)

MongoDB中除了支持MapReduce的处理外，还可以利用聚合操作实现声明式的数据查询
```javascript

db.collection.aggregate([
    { $project : { "Tags._id" : 1 }},
    { $unwind : "$Tags" },
    { $match: {$or: [{"Tags._id":"tag1"},{"Tags._id":"tag2"}]}},
    { $group: { 
        _id : "$_id",
        count: { $sum:1 } 
    }},
    {$sort: {"count":-1}}
  ],
  {
    explain:true
  })
```

#### 3. 图状数据模型

图状数据模型主要用于实现多对多的数据关联，相对于关系数据库多对多只能满足简单的需求，图数据库往往可以实现复杂的关系网络。


比较常见的图数据库有： Neo4J，OrientDB 以及InifnitiGraph等， 图数据的一些特点包括：
- 可以很容易的扩展来适应数据结构的变化
- 每个顶点都可以连接任何顶点
- 更定某个顶点可以高效的获得所有入边和出边，从而遍历整个的图
- 对于不同类型的关系使用不同的标签，可以在单个图中存储多种不同类型的信息。

![](https://s3.amazonaws.com/dev.assets.neo4j.com/wp-content/uploads/20180711200201/twitter-users-graph-database-model-peter-emil-johan.png)@h=300


图数据库的应用场景和查询，利用关系数据库也可以实现，但是关系数据库在处理多对多的数据时候往往可能陷入编写SQL过于麻烦和执行效率低的问题，因此需要理解不同数据模型的存储优势从而找到合适的存储数据的方式。

### 第三章数据存储和检索
---

本章主要介绍数据库的存储和底层实现相关的内容，通过理解这些细节对于数据库的调优，以及针对不同工作状态下（事务性和分析性）负载下的数据库运行有更好的理解，并介绍了不同类型的数据库（关系型和NoSQL类型数据库）的存储引擎和原理。

下面是一个简单的"数据库"实现, 使用追加日志的方式写入一个文件中，尽管写入的速度比较快，但是读取的速度会随着写入的数据量的增加而逐步增加，复杂度为O(n), 为了提升速度，往往引入索引的方式提高读取效率，同时实际的数据库产品除了需要考虑速度，外还需要考虑**并发控制，回收磁盘空间，错误处理等等**复杂的问题，
```sh
#!/bin/bash
db_set(){
  echo "$1,$*" >> database.db
}

db_get(){
  grep "^$1," database.db | sed -e "s/^$1,//" | tail -n 1
}

if [ $1 = "set" ]
then
        db_set $2 $3
else
        db_get $2
fi
```

上面实现的数据库已经具备很高的写入速度了，增加索引的方式往往只会降低写入的速度，因为要对于写入的数据同时更新索引内容，**适当的索引可以加速读取效率，但是索引同时会减慢写入的速度**，这就是一个需要权衡的设计。

#### 1. 哈希索引

上面的追加K-V数据库，如果需要使用哈希索引，可以利用其在文件中的字节偏移量来存储，这样在处理查询数据的时候，直接通过内存中的位置信息，一次偏移即可获取数据。比较适合Key不太多的情况，每个Key又具有大量的写操作，这样key值就可以直接的保存在内存中处理。

对于不断写入持续增加的文件，可以通过分段，对于不同的段执行压缩算法，这样可以保持较少的数据使用情况。（毕竟包含了大量对于相同的Key的更新操作，这些都是历史数据可以执行定期的删除清理）

需要考虑的问题：
- 删除记录（可使用标记法，后续压缩处理的时候一并删除）
- 崩溃后的恢复（可以将hash map值快照到磁盘上，从磁盘恢复）
- 部分写入（校验数据）
- 并发控制（单一的写入线程）

追加比起直接的修改优势在于：

- 顺序写操作比随机写操作更快，不仅对于磁盘而言，对于SSD同样
- 并发和崩溃恢复更简单
- 防止文件出现碎片化的问题

哈希表问题在于：
- 需要写入内存，处理大量的Key的时候占用比较大
- 区间查询效率不高，不能简单的扫描一段中所有的键值(比如a000001-a100000)

#### 2. SSTables和LSM-Tree


SSTable和内存表都是Google Bigtable论文中提到的概念，后来这种方式在LevelDB, RocksDB, Cassandra以及HBash等多个存储引擎中被使用。

SSTable使用排序的方式处理上面的K-V存储，对于合并过程中，通过并发的读取多个段文件来按顺序的方式写入到输出文件，对于重复存在的键值，则利用段文件本身的时间值来更新最新的，通过排序的方式使得不需要保存每一个键的Hash值，可以每隔一写Key保存一个，扫描的时候查找最近的位置来扫描获得值是否存在。

对于磁盘上维护排序结构可以利用B-Trees来实现，对于**内存中则可以利用比如红黑树或者AVL树来保存这些数据结构，允许任意的顺序写入，实现顺序读取。**


这种方式下，存储引擎的工作方式：

- 写入的时候，添加到内存中的平衡树结构中（内存表）
- 超过一定的量后，将该数据结构体写入磁盘（已排序）成为数据库查询的一部分。
- 处理读取请求时候，先在内存中擦汗寻，然后查询最新的磁盘段文件，依次查询次新的直到找到目标或者为空
- 后台周期行的执行合并和压缩过程。

> 1. 如何解决当系统运行期间的崩溃问题？
> 可以在写入内存的时候，同时追加到日志中，可以以随机的顺序保存， 仅仅在服务崩溃的时候用于恢复使用。

> 2. 如何解决数据库中不存在一些键值的问题?
> 利用布隆过滤器来实现高效的不存在的数据返回，节省查询的流程（对于每个文件执行查询，直到数据库查询不到）


**基于合并和压缩排序文件原理的存储引擎一般称为LSM存储引擎** ，这种方式使得数据集合可以远大于内存，有效支持区间查询，且具有比较高的写入吞吐量。



#### 3. B-trees

学习链接
[1.busying-oneself-with-b-trees](https://medium.com/basecs/busying-oneself-with-b-trees-78bbf10522e7)
[2. 可视化B-trees](https://www.cs.usfca.edu/~galles/visualization/BTree.html)

B-trees是几乎所有关系数据库的标准索引实现，是一种自平衡树结构，允许多个子节点，利用将数据库分解为固定大小的块或者页，传统大小为4Kb， 与前面的LSM引擎不同的是其会直接覆盖修改原始的磁盘文件，而LSM-tree则只会追加更新文件，而不会修改文件，

为了防止崩溃恢复，一般数据库在实现B-tree时候会利用预写日志的方式（WAL）来重做日志，这是一个仅仅支持追加修改的文件，每个文件修改需要先更新WAL再去更新本身的页数据。

另外直接修改页数据也会导致并发控制比较麻烦，一般使用使用**锁结合日志结构化的方式来保护数据**更简单，后台执行合并，不会影响查询。


一些数据库LMDB等不适用覆盖页和维护WAL是西安崩溃恢复，而是使用写时复制的方式，修改的页写入新的位置，父页指向该位置实现这种方式又被称为B+树


#### 3. B-tree和LSM-tree对比


B-tree至少需要写入两次（预写日志和写入页本身），LSM反复的压缩和SSTable的也会导致日志结构索引重新数据多次，**这种一次数据写入请求引发的多次磁盘写入的问题，称为写放大问题，对于SSD磁盘，具有有限的擦除次数下，更需要关注。**


LSM可以降低磁盘碎片的问题，降低存储开销，磁盘上的文件一般回避B-tree要小很多，同时可以承受更高的写入吞吐量（写放大的问题比较低，且写入文件比较紧凑）

**LSM的压缩一般较为昂贵，可能会影响实际的查询，而且如果写入速率过高，压缩速率无法匹配会导致未合并的数据越来越多，影响查询和磁盘使用，导致系统的崩溃。**

B-tree往往具有比较好的事务处理能力，在多个使用场景下提供良好的性能。根据使用的场景实际的测试来判断哪种更加合适。


#### 4. 其他索引结构

在MySQL InnoDB存储引擎中，表的主键始终使用聚集索引（在索引中直接保存行的数据）二级索引引用主键。

对于查询表中的多列，可以使用多列索引，又称为级联索引，将一列追加到另一列中，但是需要注意查询的顺序，往往索引具有特殊的顺序来保存数据内容

多维索引则可以实现不依赖于顺序的多列查询，比如地理位置中经纬度的范围查询，具体的实现如R树或者广义搜索树索引。

 #### 5. 事务处理和分析
 
 OLTP: 在线事务处理，常规的用户查询，搜索更新数据的过程，基于键值进行拆线呢，随机访问，终端用户使用等特点
 OLAP: 在线分析处理，用于统计分析工作，决策使用，通常对于大量记录进行汇总，使用ETL导入，维度较高。
 
 下图给出的是OLTP和ETL以及OLAP的流程图，中心数据仓库对于小的企业来说可能不存在，数据量不大的情况下，直接利用数据库本身的OLAP进行统计分析即可，但是当数据越来越多，不同的数据库相互独立的，就需要一个中心式的数据仓库进行管理。**数据仓库包含企业所有OLTP系统的数据只读副本，从这些数据副本中提取数据，转换为分析友好的模式，执行必要的清理加载到数据仓库中**
 

 
 ![](https://edge.uacdn.net/JCHE7X330JOSJK43077U/images/2.jpeg?w=768&fm=webp&q=25)
 
  比如Hive,Spark SQL以及Impala等开源系统都可以用来管理数据仓库，另外一些商业的比如Teradata，Amazon(RedShift)等等， 提供类似于SQL查询的方式来管理数据仓库，提供业务使用
 
 数据仓库往往数据维度较高，一个表可能具有上百列，但是一般会包含事件的对象，关联对象，发生的时间，方法，原因以及信息，便于分析。
 
**列存储**：在传统的面向行存储的系统中，每次查询都会导致将所有行数据载入内存，解析并过滤数据，而面向列存储的则通过将不同的列存储在独立的文件中来加速查询，每个文件以相同顺序保存数据行，
 
 
 
 ![](http://www.dbbest.com/wp-content/uploads/2012/07/column-oriented-database.jpg)
 
 列存储还可以借助于压缩算法实现存储的优化，比如对于一列数据如果具有特定的值，可以使用位图的方式存储，节省存储空间，
 面向列的存储，压缩和排序都有助于加速读取查询，但是也会使得写入比较困难，可以借助于LSM-tree的方式来更新数据，
 
 > 数据仓库中可以使用视图的方式来管理数据，实现高效的查询，批量操作实现更新。



### 第四章 数据编码与演化
---

本章节介绍了一些常见的数据编码方式以及处理方式，并比较了不同的编码方式使用的优势和所存在的问题。

- **向后兼容**：比较新的代码可以读取老的程序写入的数据（比较容易实现，毕竟程序升级过程中对于原系统比较熟悉，变更的时候都会考虑）
- **向前兼容**:  老的版本代码可以读取新的程序写入的数据（一般通过忽略的方式实现兼容）

许多编程语言内置将内存的对象编码为字节序列的方式比如Python的Pickle， Rube的Marshal等。但是这些方式除了兼容性不太好外（不同的程序语言读取的时候会有问题），总是会出现各种各样的安全问题，比如远程执行代码

#### 1. JSON， XML以及二进制方式

JSON存储的空间占用比XML要更好一些，且原生Web支持，因此使用的更广泛，相对于XML和CSV提供字符串和数字的区分，但是无法区分整数和浮点数，不指定精度
JSON,XML 本身不支持二进制，可以使用BASE64实现编码后保存，但是这样存储的效率会大幅度降低（33%）

二进制方式比如： Protobuf, MessagePack(编码JSON数据)，Avro以及Thrift等，按照不同的编码方式来编码数据，比如下面为Protobuf执行编码的示意图
```
{
 "userName":"Martin",
 "favoriteNumber": 1337，
 "interests"：[“daydreaming”,"hacking"],
}
```

![](https://martin.kleppmann.com/2012/12/protobuf_small.png)

相对于使用文本直接保存的JSON对象占用空间约70字节左右，而使用Protobuf的存储空间仅仅33字节，因为并没有保存任何的属性名称，而是使用tag的方式来区分不同的属性，即便是修改了属性的名称，只要位置没有发生变化， 不影响数据的序列化操作

Thrift 为Facebook开发，提供两种不同的编码方式，编码后的大小与Protobuf基本相近。

> 不同的编码方式在使用和版本上需要注意的问题？

- 可添加新的字段，需要给与一个新的标记号码
- 旧的代码可以读取新的代码产生的数据（注释跳过的方式）
- 不能随便更改字段的标签
- 新添加的字段不能设置required属性，添加字段必须是可选的或有默认值
- 删除的时候同样需要注意requred属性
- 改变类型可以，但是有可能会导致数据精度问题或者截断


Avro编码方式是另一种独特的二进制编码。通过使用不同的读写模式来管理数据的序列化操作，网络中通过协商模式来传输数据，数据库中可以保存不同版本的模式来同时由多个模式写入的数据，

> Avro的优势？

- 动态生成模式更友好，可以利用自定义的模式对于数据库中的关系进行处理，存储编码。可以将数据库表的每一列作为一个Avro字段记录模式存储编码。
- 更新数据库后，可以直接修改Avro的模式来管理数据的导入和导出，而使用PB或者Thrift则可能需要手动的修改标签，适配变化。
- LinkedIn的Espresso使用Avro来编码数据

PB以及Avro都提供了一些静态编程中的代码生成，自动帮助检查类型，方便编写程序

#### 2. 数据流模式

应用程序在升级的过程中，可能会存在不同的版本下对于数据库的操作，因此需要保证应用的向前兼容，也就是程序需要忽略新版本中增加的数据库新的字段，但是注意保证旧版本的更新不会导致数据的丢失，一些旧版本的应用程序比如执行保存的数据，可能导致新版本的数据设置为缺省值。

REST和SOAP是两种流行的Web服务：
- SOAP使用XML协议，而REST则更多的借助于HTTP(不限于)
- SOAP带有大量标准，使用SOAP Web服务的API称为 WSDL来描述，支持代码生成
- SOAP消息过于复杂，难以手动构建，一般依赖于工具，IDE
- RESTAPI则更简单，代码清晰简练

> 使用RPC处理数据的问题？

- 远程环境不可预测
- 相对于本地的程序，可能出现超时
- 重复发送，可能导致重复的执行
- 延迟会较高
- 不同的编程语言，在数据结构上可能不一致，类型不一致


gRPC支持流，可以接收一段时间内的一系列请求,RPC请求一般侧重于同一个组织内的服务之间的请求，发送在一个数据中心内部， 跨组织边界的通信，可能会导致各种问题，调试不太方便（RESTAPI更简单一些）

> 消息代理的方式与直接的RPC相比较具有的几个优点？

1. 具有缓存的能力，提高可靠性
2. 消息重发的能力，防止崩溃后丢失
3. 发送方和接收方的解耦
4. 可以支持广播模式

常见的消息代理，RabbitMQ以及ActiveMQ， Kafaka等 可以独立的更改发布者和消费者，部署更加简单。


#### 3， Actor模型

Actor模型并不限于单一的节点，在分布式中也可以实现，集成了消息代理和Actor模型，Actor模型假定消息可能会丢失，不管是本地还是远程节点， 都是用相同的消息传递机制，如果不在一个节点，则通过编码经过网络发送出去

每个Actor之间都可以通信，每个Actor具有自己的标记属性 ， 每一个都运行在独立的内存空间中，私有的数据内容不会被其他的Actor改变。 

每个处理逻辑都被封装在一个Actor中，相当于一个任务调度单元，通过彼此之间的通信来协调任务的处理，使用顶层的调度实现管理，每一个都相互独立的运行，即便是出现异常也不会导致整个系统的奔溃，从而实现一个自愈的结构

https://www.brianstorti.com/the-actor-model/

https://youtu.be/7erJ1DV_Tlo